{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'wurlitzer', 'infomap', 'graph_tool', 'karateclub', 'leidenalg'}\n",
      "Note: to be able to use all overlapping methods, you need to install some additional packages:  {'ASLPAw', 'karateclub'}\n",
      "Note: to be able to use all bipartite methods, you need to install some additional packages:  {'infomap', 'leidenalg', 'wurlitzer'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "from cdlib import algorithms, classes, evaluation, readwrite\n",
    "\n",
    "class SpotifyGraph():\n",
    "\n",
    "    def __init__(self, dir, features_dir):\n",
    "\n",
    "        self.base_dir = path.join(dir, \"dataset\")\n",
    "        self.save_dir = path.join(dir, \"results\")\n",
    "        self.tracks_pth = path.join(self.base_dir, \"tracks.json\")\n",
    "        self.col_pth = path.join(self.base_dir, \"collections.json\")\n",
    "        self.graph_pth = path.join(self.base_dir, \"filtered_graph.json\")\n",
    "\n",
    "        self.ft_dir = features_dir\n",
    "        self.features_dict = {}\n",
    "\n",
    "        self.load()\n",
    "\n",
    "    def load(self):\n",
    "        print(\"Loading graph...\")\n",
    "        # with open(self.tracks_pth, \"r\", encoding=\"utf-8\") as f:\n",
    "        #     self.tracks = json.load(f)\n",
    "        with open(self.col_pth, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.collections = json.load(f)\n",
    "        # with open(self.graph_pth, \"r\", encoding=\"utf-8\") as f:\n",
    "        #     self.graph = json.load(f)\n",
    "\n",
    "    def save_graph(self, G):\n",
    "        with open(path.join(self.base_dir, \"filtered_graph.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(dict(tracks=[n for n in G.nodes() if n in self.track_ids_deg.keys()],\n",
    "                           collections=[n for n in G.nodes() if n in self.col_ids_deg.keys()],\n",
    "                           edges=[{\"from\" : u, \"to\" : v} for u,v in G.edges()]),\n",
    "                           f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    def to_nx_graph(self):\n",
    "        '''Get dataset as a NetworkX graph.'''\n",
    "        \n",
    "        g = nx.Graph()\n",
    "        g.add_nodes_from(self.graph[\"collections\"], bipartite=0)\n",
    "        g.add_nodes_from(self.graph[\"tracks\"], bipartite=1) \n",
    "        edge_tuples = [ (e[\"from\"], e[\"to\"]) for e in self.graph[\"edges\"] ] \n",
    "        g.add_edges_from( edge_tuples )\n",
    "\n",
    "        self.track_ids_deg = {i : g.degree[i] for i in self.graph[\"tracks\"]}\n",
    "        self.col_ids_deg = {i : g.degree[i] for i in self.graph[\"collections\"]}\n",
    "\n",
    "        return g#, track_ids_deg, col_ids_deg\n",
    "\n",
    "    def filter_graph(self, g, deg=1):\n",
    "        print(\"Removing nodes with k<={}...\".format(deg))\n",
    "        print(\"Num nodes before filter: {}\".format(len(g.nodes)))\n",
    "        nodes_to_remove = [i for (i, d) in self.track_ids_deg.items() if d <= deg]\n",
    "        g.remove_nodes_from(nodes_to_remove)\n",
    "        print(\"Num nodes after filter: {}\".format(len(g.nodes)))\n",
    "        largest_cc = max(nx.connected_components(g), key=len)\n",
    "        print(\"Largest 5 CCs: \", [len(c) for c in sorted(nx.connected_components(g), key=len, reverse=True)][:5])\n",
    "        print(\"Num nodes final: {}\".format(len(largest_cc)))\n",
    "        print(\"Saving new graph...\")\n",
    "        self.save_graph(g.subgraph(largest_cc))\n",
    "\n",
    "\n",
    "    def get_playlists_vs_albums(self):\n",
    "        playlist_ids, album_ids = [],[]\n",
    "        for id,info in self.collections.items():\n",
    "            if \"playlist\" in info[\"type\"]:\n",
    "                playlist_ids.append(id)\n",
    "            elif \"album\" in info[\"type\"]:\n",
    "                album_ids.append(id)\n",
    "\n",
    "        return playlist_ids, album_ids\n",
    "    \n",
    "    def get_playlists_by_keywords(self, keywords):\n",
    "        playlist_ids = []\n",
    "\n",
    "        def keywords_in_info(keywords, info):\n",
    "            return True if (any(word in info[\"name\"].lower() for word in keywords) or \\\n",
    "                            any(word in info[\"description\"].lower() for word in keywords)) else False\n",
    "\n",
    "        for id,info in self.collections.items():\n",
    "            if \"playlist\" in info[\"type\"] and keywords_in_info(keywords, info):\n",
    "                playlist_ids.append(id)\n",
    "\n",
    "        return playlist_ids\n",
    "    \n",
    "    def get_projected_graph(self, graph, is_multigraph=False):\n",
    "        nodes_for_projection = [n for n, a in graph.nodes(data=True) if a[\"bipartite\"]==1]\n",
    "        print(\"Projecting on {} nodes\".format(len(nodes_for_projection)))\n",
    "        G_projected = bipartite.projected_graph(graph, nodes_for_projection, multigraph=is_multigraph)\n",
    "        return G_projected\n",
    "    \n",
    "    def save_community(self, pred, algo_name):\n",
    "        readwrite.write_community_csv(pred, path.join(self.save_dir, \"{}_communities.csv\".format(algo_name)), \",\")\n",
    "\n",
    "    def find_communities(self, g, algorithm):\n",
    "        algorithm_name = algorithm.__name__\n",
    "        try:\n",
    "            print(\"Starting community detection for {} algorithm\".format(algorithm_name))\n",
    "            if algorithm_name == \"overlapping_seed_set_expansion\":\n",
    "                #list of nodes as seeds (preferably each in different community)\n",
    "                list_of_seeds = []\n",
    "                community_prediction = algorithm(g, seeds=list_of_seeds)\n",
    "            else:\n",
    "                community_prediction = algorithm(g)\n",
    "            print(\"Saving...\")\n",
    "            self.save_community(community_prediction, algorithm_name)\n",
    "        except Exception as e:\n",
    "            print(\"Error with {} algorithm\".format(algorithm_name))\n",
    "            print(type(e), e)\n",
    "        else:\n",
    "            print(\"Saved communities file for {} algorithm\".format(algorithm_name))\n",
    "\n",
    "    def find_common_keywords(self):\n",
    "        all_keywords = defaultdict(int)\n",
    "        for id, info in tqdm(self.collections.items()):\n",
    "            if \"playlist\" in info[\"type\"]:\n",
    "                if \"<a href=:\" in info[\"description\"]:\n",
    "                    decription = []\n",
    "                    for i in info[\"description\"].split(\", \"):\n",
    "                        decription += i.lower().split(\">\")[1].split(\"</a\")[0].split()\n",
    "                else:\n",
    "                    decription = info[\"description\"].lower()\\\n",
    "                                .replace(\"(\",\"\").replace(\")\",\"\").replace(\"{\",\"\").replace(\"}\",\"\")\\\n",
    "                                .replace(\"[\",\"\").replace(\"]\",\"\").replace(\"!\",\"\").replace(\"?\",\"\")\\\n",
    "                                .replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\"\").replace(\".\",\"\")\\\n",
    "                                .replace(\"-\",\"\").replace(\"–\",\"\").replace(\";\",\"\").replace(\":\",\"\")\\\n",
    "                                .replace(\"&\",\"\").replace(\"%\",\"\").replace(\"/\",\"\").replace(\"\\\\\",\"\")\\\n",
    "                                .replace(\"$\",\"\").replace(\"|\",\"\").split()\n",
    "\n",
    "                name = info[\"name\"].lower()\\\n",
    "                                .replace(\"(\",\"\").replace(\")\",\"\").replace(\"{\",\"\").replace(\"}\",\"\")\\\n",
    "                                .replace(\"[\",\"\").replace(\"]\",\"\").replace(\"!\",\"\").replace(\"?\",\"\")\\\n",
    "                                .replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\"\").replace(\".\",\"\")\\\n",
    "                                .replace(\"-\",\"\").replace(\"–\",\"\").replace(\";\",\"\").replace(\":\",\"\")\\\n",
    "                                .replace(\"&\",\"\").replace(\"%\",\"\").replace(\"/\",\"\").replace(\"\\\\\",\"\")\\\n",
    "                                .replace(\"$\",\"\").replace(\"|\",\"\").split()\n",
    "                \n",
    "                for word in name + decription:\n",
    "                    all_keywords[word] += 1\n",
    "        \n",
    "        \n",
    "        with open(path.join(self.base_dir, \"phrases.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(dict(phrases=dict(sorted(all_keywords.items(), key=lambda item: item[1], reverse=True))), \\\n",
    "                            f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # Example usage of the SpotifyGraph dataset class\n",
    "    \n",
    "\n",
    "    # JSON COLLECTIONS STRUCTURE FOR EACH PLAYLIST - example\n",
    "    # \"type\": \"playlist\",\n",
    "    # \"name\": \"Adrenaline Workout\",\n",
    "    # \"num_tracks\": 31,\n",
    "    # \"description\": \"If your workout doubles as an outlet for your aggression\",\n",
    "    # \"ztracks\": [ track ids ]\n",
    "\n",
    "\n",
    "# to je iz hw3 sam sample \n",
    "\n",
    "            # g = girvan_newman_graph(mi)\n",
    "            # louvain = algorithms.louvain(g)\n",
    "            # walktrap = algorithms.walktrap(g)\n",
    "            # label_prop = algorithms.label_propagation(g)\n",
    "            # true_labels = classes.NodeClustering([[3*i + j for i in range(24)] for j in range(3)], g)\n",
    "\n",
    "            # a += evaluation.normalized_mutual_information(true_labels, louvain).score\n",
    "            # b += evaluation.normalized_mutual_information(true_labels, walktrap).score\n",
    "            # c += evaluation.normalized_mutual_information(true_labels, label_prop).score\n",
    "\n",
    "            ##############################################################################\n",
    "\n",
    "            # truth = [[i for i in range(1000)]]\n",
    "            # g = nx.gnm_random_graph(1000, 1000*k)\n",
    "            # true_labels = classes.NodeClustering(truth, g)\n",
    "            # louvain = algorithms.louvain(g)\n",
    "            # walktrap = algorithms.walktrap(g)\n",
    "            # label_prop = algorithms.label_propagation(g)\n",
    "\n",
    "            # a += evaluation.variation_of_information(true_labels, louvain).score\n",
    "            # b += evaluation.variation_of_information(true_labels, walktrap).score\n",
    "            # c += evaluation.variation_of_information(true_labels, label_prop).score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153801/153801 [00:00<00:00, 438956.71it/s]\n"
     ]
    }
   ],
   "source": [
    "root = os.getcwd()\n",
    "data = SpotifyGraph(root, None)\n",
    "# g = data.to_nx_graph()\n",
    "# print(\"Num nodes:\", len(g))\n",
    "data.find_common_keywords()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing nodes with k<=9...\n",
      "Num nodes before filter: 1563358\n",
      "Num nodes after filter: 189514\n",
      "Largest 5 CCs:  [120333, 23, 21, 15, 12]\n",
      "Num nodes final: 120333\n",
      "Saving new graph...\n"
     ]
    }
   ],
   "source": [
    "# if you already have filtered graph you can skip this\n",
    "data.filter_graph(g, deg=9)\n",
    "# largest_cc = max(nx.connected_components(g), key=len)\n",
    "# g = g.subgraph(largest_cc)\n",
    "# print(len(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting projection...\n",
      "Projecting on 6006 nodes\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting projection...\")\n",
    "g = data.get_projected_graph(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting community detection...\n",
      "\n",
      "Starting community detection for aslpaw algorithm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/lukak/UNI/ina/ina-project/test.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000004vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStarting community detection...\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000004vscode-remote?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m algo \u001b[39min\u001b[39;00m list_of_overlapping_algorithms:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000004vscode-remote?line=9'>10</a>\u001b[0m     data\u001b[39m.\u001b[39;49mfind_communities(g, algo)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000004vscode-remote?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m()\n",
      "\u001b[1;32m/home/lukak/UNI/ina/ina-project/test.ipynb Cell 1'\u001b[0m in \u001b[0;36mSpotifyGraph.find_communities\u001b[0;34m(self, g, algorithm)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000000vscode-remote?line=105'>106</a>\u001b[0m     community_prediction \u001b[39m=\u001b[39m algorithm(g, seeds\u001b[39m=\u001b[39mlist_of_seeds)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000000vscode-remote?line=106'>107</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000000vscode-remote?line=107'>108</a>\u001b[0m     community_prediction \u001b[39m=\u001b[39m algorithm(g)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000000vscode-remote?line=108'>109</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSaving...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000000vscode-remote?line=109'>110</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_community(community_prediction, algorithm_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/algorithms/overlapping_partition.py:1267\u001b[0m, in \u001b[0;36maslpaw\u001b[0;34m(g_original)\u001b[0m\n\u001b[1;32m   <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/algorithms/overlapping_partition.py?line=1261'>1262</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/algorithms/overlapping_partition.py?line=1262'>1263</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOptional dependency not satisfied: install gmpy (conda install gmpy2) and ASLPAw (pip install shuffle_graph>=2.1.0 similarity-index-of-label-graph>=2.0.1 ASLPAw>=2.1.0). If using a notebook, you need also to restart your runtime/kernel.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/algorithms/overlapping_partition.py?line=1263'>1264</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/algorithms/overlapping_partition.py?line=1265'>1266</a>\u001b[0m g \u001b[39m=\u001b[39m convert_graph_formats(g_original, nx\u001b[39m.\u001b[39mGraph)\n\u001b[0;32m-> <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/algorithms/overlapping_partition.py?line=1266'>1267</a>\u001b[0m coms \u001b[39m=\u001b[39m ASLPAw(g)\u001b[39m.\u001b[39madj\n\u001b[1;32m   <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/algorithms/overlapping_partition.py?line=1268'>1269</a>\u001b[0m communities \u001b[39m=\u001b[39m defaultdict(\u001b[39mlist\u001b[39m)\n\u001b[1;32m   <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/algorithms/overlapping_partition.py?line=1269'>1270</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, c \u001b[39min\u001b[39;00m coms\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/anaconda3/envs/ina/lib/python3.8/site-packages/ASLPAw_package/ASLPAw_module.py:124\u001b[0m, in \u001b[0;36mASLPAw\u001b[0;34m(data_graph, Repeat_T, seed, graph_package)\u001b[0m\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/ASLPAw_package/ASLPAw_module.py?line=89'>90</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/ASLPAw_package/ASLPAw_module.py?line=90'>91</a>\u001b[0m \u001b[39m    Returns a graph of the edges of each node with its own community tag node.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/ASLPAw_package/ASLPAw_module.py?line=91'>92</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/ASLPAw_package/ASLPAw_module.py?line=119'>120</a>\u001b[0m \u001b[39m    AdjacencyView({0: {1: {'weight': 0.9333333333333333}}, 1: {1: {'weight': 1.0}}, 2: {1: {'weight': 1.0}}, 3: {1: {'weight': 0.9666666666666667}}, 4: {1: {'weight': 1.0}}, 5: {1: {'weight': 0.9666666666666667}}, 6: {}, 7: {7: {'weight': 0.7666666666666667}}, 8: {}, 9: {13: {'weight': 0.4}, 6: {'weight': 0.26666666666666666}}, 13: {13: {'weight': 0.6333333333333333}}, 10: {1: {'weight': 0.5666666666666667}}, 11: {7: {'weight': 0.6333333333333333}}, 12: {12: {'weight': 0.4666666666666667}, 13: {'weight': 0.4}}, 14: {13: {'weight': 0.5666666666666667}}, 15: {13: {'weight': 0.5333333333333333}, 12: {'weight': 0.3333333333333333}}, 16: {13: {'weight': 0.43333333333333335}}, 17: {13: {'weight': 0.43333333333333335}, 12: {'weight': 0.4}}})\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/ASLPAw_package/ASLPAw_module.py?line=120'>121</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/ASLPAw_package/ASLPAw_module.py?line=122'>123</a>\u001b[0m \u001b[39mif\u001b[39;00m graph_package \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mNetworkX\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/ASLPAw_package/ASLPAw_module.py?line=123'>124</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _ASLPAw_networkx(data_graph, Repeat_T, seed)\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/ASLPAw_package/ASLPAw_module.py?line=124'>125</a>\u001b[0m \u001b[39melif\u001b[39;00m graph_package \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mSNAP\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/ASLPAw_package/ASLPAw_module.py?line=125'>126</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ina/lib/python3.8/site-packages/ASLPAw_package/ASLPAw_module.py:73\u001b[0m, in \u001b[0;36m_ASLPAw_networkx\u001b[0;34m(data_graph, Repeat_T, seed)\u001b[0m\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/ASLPAw_package/ASLPAw_module.py?line=69'>70</a>\u001b[0m similarity_index_of_label_graph \u001b[39m=\u001b[39m similarity_index_of_label_graph_class()\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/ASLPAw_package/ASLPAw_module.py?line=71'>72</a>\u001b[0m \u001b[39mfor\u001b[39;00m _t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(Repeat_T):\n\u001b[0;32m---> <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/ASLPAw_package/ASLPAw_module.py?line=72'>73</a>\u001b[0m     data_graph \u001b[39m=\u001b[39m shuffle_graph(data_graph)\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/ASLPAw_package/ASLPAw_module.py?line=73'>74</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data_graph_node, dict_of_adjvex \u001b[39min\u001b[39;00m data_graph\u001b[39m.\u001b[39madjacency():\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/ASLPAw_package/ASLPAw_module.py?line=74'>75</a>\u001b[0m         weight_of_community_label_for_adjvex \u001b[39m=\u001b[39m count_dict()\n",
      "File \u001b[0;32m~/anaconda3/envs/ina/lib/python3.8/site-packages/shuffle_graph_package/shuffle_graph_module.py:67\u001b[0m, in \u001b[0;36mshuffle_graph\u001b[0;34m(data_graph, seed, prng_type)\u001b[0m\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/shuffle_graph_package/shuffle_graph_module.py?line=63'>64</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnetworkx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconvert\u001b[39;00m \u001b[39mimport\u001b[39;00m from_dict_of_dicts\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/shuffle_graph_package/shuffle_graph_module.py?line=65'>66</a>\u001b[0m list_of_nodes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(data_graph\u001b[39m.\u001b[39mnodes)\n\u001b[0;32m---> <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/shuffle_graph_package/shuffle_graph_module.py?line=66'>67</a>\u001b[0m pr_complete_shuffle(list_of_nodes, seed, prng_type)\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/shuffle_graph_package/shuffle_graph_module.py?line=67'>68</a>\u001b[0m new_order_data_graph \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/shuffle_graph_package/shuffle_graph_module.py?line=68'>69</a>\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m list_of_nodes:\n",
      "File \u001b[0;32m~/anaconda3/envs/ina/lib/python3.8/site-packages/complete_shuffle_package/complete_shuffle_module.py:201\u001b[0m, in \u001b[0;36mpr_complete_shuffle\u001b[0;34m(x, seed, prng_type, additional_hash)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/complete_shuffle_package/complete_shuffle_module.py?line=198'>199</a>\u001b[0m     prng_instance \u001b[39m=\u001b[39m pure_prng(seed, prng_type, new_prng_period, additional_hash)\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/complete_shuffle_package/complete_shuffle_module.py?line=199'>200</a>\u001b[0m     prng_instance_rand_int \u001b[39m=\u001b[39m prng_instance\u001b[39m.\u001b[39mrand_int\n\u001b[0;32m--> <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/complete_shuffle_package/complete_shuffle_module.py?line=200'>201</a>\u001b[0m     _shuffle(x, prng_instance_rand_int)\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/complete_shuffle_package/complete_shuffle_module.py?line=201'>202</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/complete_shuffle_package/complete_shuffle_module.py?line=202'>203</a>\u001b[0m     prng_period \u001b[39m=\u001b[39m algorithm_characteristics_parameter[\u001b[39m'\u001b[39m\u001b[39mprng_period\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/ina/lib/python3.8/site-packages/complete_shuffle_package/complete_shuffle_module.py:38\u001b[0m, in \u001b[0;36m_shuffle\u001b[0;34m(x, randint)\u001b[0m\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/complete_shuffle_package/complete_shuffle_module.py?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(x) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/complete_shuffle_package/complete_shuffle_module.py?line=36'>37</a>\u001b[0m     rand_int \u001b[39m=\u001b[39m randint(i)\n\u001b[0;32m---> <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/complete_shuffle_package/complete_shuffle_module.py?line=37'>38</a>\u001b[0m     random_location \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(rand_int)\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/complete_shuffle_package/complete_shuffle_module.py?line=38'>39</a>\u001b[0m     x[i], x[random_location] \u001b[39m=\u001b[39m x[random_location], x[i]\n",
      "File \u001b[0;32m~/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py:685\u001b[0m, in \u001b[0;36mpure_prng.rand_int\u001b[0;34m(self, b, a, unbias, new_period)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py?line=682'>683</a>\u001b[0m \u001b[39mif\u001b[39;00m unbias:\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py?line=683'>684</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py?line=684'>685</a>\u001b[0m         \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m ((random_number\u001b[39m:=\u001b[39m \u001b[39mnext\u001b[39;49m(random_number_method) \u001b[39m&\u001b[39m difference_bit_mask) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m difference_value): \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py?line=685'>686</a>\u001b[0m         \u001b[39myield\u001b[39;00m a \u001b[39m+\u001b[39m random_number\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py?line=686'>687</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py:497\u001b[0m, in \u001b[0;36mpure_prng.source_random_number\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py?line=494'>495</a>\u001b[0m hash_result \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py?line=495'>496</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(output_width):\n\u001b[0;32m--> <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py?line=496'>497</a>\u001b[0m     hash_result \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(hash_callable) \u001b[39m<<\u001b[39m (hash_size \u001b[39m*\u001b[39m i)\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py?line=498'>499</a>\u001b[0m \u001b[39mif\u001b[39;00m additional_hash_callable \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py?line=499'>500</a>\u001b[0m     hash_result \u001b[39m=\u001b[39m additional_hash_callable(hash_result, hash_size)\n",
      "File \u001b[0;32m~/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py:278\u001b[0m, in \u001b[0;36mpure_prng.__quadratic_congruential_generator\u001b[0;34m(self, algorithm_characteristics_parameter)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py?line=275'>276</a>\u001b[0m m \u001b[39m=\u001b[39m algorithm_characteristics_parameter[\u001b[39m'\u001b[39m\u001b[39mhash_size\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py?line=276'>277</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(algorithm_characteristics_parameter[\u001b[39m'\u001b[39m\u001b[39mhash_period\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m--> <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py?line=277'>278</a>\u001b[0m     x \u001b[39m=\u001b[39m rng_util\u001b[39m.\u001b[39mbit_length_mask(((x\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m2\u001b[39;49m)\u001b[39m<<\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m ((x\u001b[39m<<\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m-\u001b[39mx) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, m)\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py?line=278'>279</a>\u001b[0m     \u001b[39myield\u001b[39;00m x\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/pure_prng_package/pure_prng_module.py?line=279'>280</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThe number of times it is generated exceeds the number of hash period.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_of_overlapping_algorithms = [algorithms.aslpaw, \n",
    "                                  #algorithms.dcs, \n",
    "                                  #algorithms.lais2,\n",
    "                                  #algorithms.overlapping_seed_set_expansion,\n",
    "                                  algorithms.umstmo,\n",
    "                                  algorithms.percomvc,\n",
    "                                  ]\n",
    "print(\"Starting community detection...\\n\")\n",
    "for algo in list_of_overlapping_algorithms:\n",
    "    data.find_communities(g, algo)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # GT_IDS for evaluation after community detection\n",
    "    #playlist_ids, album_ids = dataset.get_playlists_vs_albums()\n",
    "\n",
    "\n",
    "    # hand picked filter words that occour in name or description of the playlists\n",
    "    #keywords = [\"fitness\", \"workout\"]       \n",
    "    #selected_ids = dataset.get_playlists_by_keywords(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "481f671b25a3de7ce29310ade63732b5e6b538537deca2ea013019a2a265f36c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
