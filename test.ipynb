{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'infomap', 'leidenalg', 'karateclub', 'graph_tool', 'wurlitzer'}\n",
      "Note: to be able to use all overlapping methods, you need to install some additional packages:  {'ASLPAw', 'karateclub'}\n",
      "Note: to be able to use all bipartite methods, you need to install some additional packages:  {'leidenalg', 'infomap', 'wurlitzer'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "import json\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "from cdlib import algorithms, classes, evaluation, readwrite\n",
    "\n",
    "class SpotifyGraph():\n",
    "\n",
    "    def __init__(self, dir, features_dir):\n",
    "\n",
    "        self.base_dir = path.join(dir, \"dataset\")\n",
    "        self.save_dir = path.join(dir, \"results\")\n",
    "        self.tracks_pth = path.join(self.base_dir, \"tracks.json\")\n",
    "        self.col_pth = path.join(self.base_dir, \"collections.json\")\n",
    "        self.graph_pth = path.join(self.base_dir, \"graph.json\")\n",
    "\n",
    "        self.ft_dir = features_dir\n",
    "        self.features_dict = {}\n",
    "\n",
    "        self.load()\n",
    "\n",
    "    def load(self):\n",
    "        print(\"Loading graph...\")\n",
    "        with open(self.tracks_pth, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.tracks = json.load(f)\n",
    "        with open(self.col_pth, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.collections = json.load(f)\n",
    "        with open(self.graph_pth, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.graph = json.load(f)\n",
    "\n",
    "    def save_graph(self, G):\n",
    "        with open(path.join(self.base_dir, \"graph.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(dict(tracks=[n for n in G.nodes() if n not in self.col_ids_deg.keys()],\n",
    "                           collections=[n for n in G.nodes() if n in self.col_ids_deg.keys()],\n",
    "                           edges=[{\"from\" : u, \"to\" : v} for u,v in G.edges()]),\n",
    "                           f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    def to_nx_graph(self):\n",
    "        '''Get dataset as a NetworkX graph.'''\n",
    "        \n",
    "        g = nx.Graph()\n",
    "        g.add_nodes_from(self.graph[\"collections\"], bipartite=0)\n",
    "        g.add_nodes_from(self.graph[\"tracks\"], bipartite=1) \n",
    "        edge_tuples = [ (e[\"from\"], e[\"to\"]) for e in self.graph[\"edges\"] ] \n",
    "        g.add_edges_from( edge_tuples )\n",
    "\n",
    "        self.track_ids_deg = {i : g.degree[i] for i in self.graph[\"tracks\"]}\n",
    "        self.col_ids_deg = {i : g.degree[i] for i in self.graph[\"collections\"]}\n",
    "\n",
    "        return g#, track_ids_deg, col_ids_deg\n",
    "\n",
    "    def filter_graph(self, g, deg=1):\n",
    "        print(\"Removing nodes with k<={}...\".format(deg))\n",
    "        print(\"Num nodes before filter: {}\".format(len(g.nodes)))\n",
    "        nodes_to_remove = [i for (i, d) in self.track_ids_deg.items() if d <= deg]\n",
    "        g.remove_nodes_from(nodes_to_remove)\n",
    "        print(\"Num nodes after filter: {}\".format(len(g.nodes)))\n",
    "        largest_cc = max(nx.connected_components(g), key=len)\n",
    "        print(\"Largest 5 CCs: \", [len(c) for c in sorted(nx.connected_components(g), key=len, reverse=True)][:5])\n",
    "        print(\"Num nodes final: {}\".format(len(largest_cc)))\n",
    "        print(\"Saving new graph...\")\n",
    "        self.save_graph(g.subgraph(largest_cc))\n",
    "\n",
    "\n",
    "    def get_playlists_vs_albums(self):\n",
    "        playlist_ids, album_ids = [],[]\n",
    "        for id,info in self.collections.items():\n",
    "            if \"playlist\" in info[\"type\"]:\n",
    "                playlist_ids.append(id)\n",
    "            elif \"album\" in info[\"type\"]:\n",
    "                album_ids.append(id)\n",
    "\n",
    "        return playlist_ids, album_ids\n",
    "    \n",
    "    def get_playlists_by_keywords(self, keywords):\n",
    "        playlist_ids = []\n",
    "\n",
    "        def keywords_in_info(keywords, info):\n",
    "            return True if (any(word in info[\"name\"].lower() for word in keywords) or \\\n",
    "                            any(word in info[\"description\"].lower() for word in keywords)) else False\n",
    "\n",
    "        for id,info in self.collections.items():\n",
    "            if \"playlist\" in info[\"type\"] and keywords_in_info(keywords, info):\n",
    "                playlist_ids.append(id)\n",
    "\n",
    "        return playlist_ids\n",
    "    \n",
    "    def get_projected_graph(self, graph, is_multigraph=False):\n",
    "        G_projected = bipartite.projected_graph(graph,[n for n, a in graph.nodes(data=True) if a[\"bipartite\"]==1], multigraph=is_multigraph)\n",
    "        return G_projected\n",
    "    \n",
    "    def save_community(self, pred, algo_name):\n",
    "        readwrite.write_community_csv(pred, path.join(self.save_dir, \"{}_communities.csv\".format(algo_name)), \",\")\n",
    "\n",
    "    def find_communities(self, g, algorithm):\n",
    "        algorithm_name = algorithm.__name__\n",
    "        try:\n",
    "            print(\"Starting community detection for {} algorithm\".format(algorithm_name))\n",
    "            if algorithm_name == \"overlapping_seed_set_expansion\":\n",
    "                #list of nodes as seeds (preferably each in different community)\n",
    "                list_of_seeds = []\n",
    "                community_prediction = algorithm(g, seeds=list_of_seeds)\n",
    "            else:\n",
    "                community_prediction = algorithm(g)\n",
    "            self.save_community(community_prediction, algorithm_name)\n",
    "        except Exception as e:\n",
    "            print(\"Error with {} algorithm\".format(algorithm_name))\n",
    "            print(type(e), e)\n",
    "        else:\n",
    "            print(\"Saved communities file for {} algorithm\".format(algorithm_name))\n",
    "\n",
    "\n",
    "    # Example usage of the SpotifyGraph dataset class\n",
    "    \n",
    "\n",
    "    # JSON COLLECTIONS STRUCTURE FOR EACH PLAYLIST - example\n",
    "    # \"type\": \"playlist\",\n",
    "    # \"name\": \"Adrenaline Workout\",\n",
    "    # \"num_tracks\": 31,\n",
    "    # \"description\": \"If your workout doubles as an outlet for your aggression\",\n",
    "    # \"ztracks\": [ track ids ]\n",
    "\n",
    "\n",
    "# to je iz hw3 sam sample \n",
    "\n",
    "            # g = girvan_newman_graph(mi)\n",
    "            # louvain = algorithms.louvain(g)\n",
    "            # walktrap = algorithms.walktrap(g)\n",
    "            # label_prop = algorithms.label_propagation(g)\n",
    "            # true_labels = classes.NodeClustering([[3*i + j for i in range(24)] for j in range(3)], g)\n",
    "\n",
    "            # a += evaluation.normalized_mutual_information(true_labels, louvain).score\n",
    "            # b += evaluation.normalized_mutual_information(true_labels, walktrap).score\n",
    "            # c += evaluation.normalized_mutual_information(true_labels, label_prop).score\n",
    "\n",
    "            ##############################################################################\n",
    "\n",
    "            # truth = [[i for i in range(1000)]]\n",
    "            # g = nx.gnm_random_graph(1000, 1000*k)\n",
    "            # true_labels = classes.NodeClustering(truth, g)\n",
    "            # louvain = algorithms.louvain(g)\n",
    "            # walktrap = algorithms.walktrap(g)\n",
    "            # label_prop = algorithms.label_propagation(g)\n",
    "\n",
    "            # a += evaluation.variation_of_information(true_labels, louvain).score\n",
    "            # b += evaluation.variation_of_information(true_labels, walktrap).score\n",
    "            # c += evaluation.variation_of_information(true_labels, label_prop).score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph...\n",
      "Num nodes: 1563358\n"
     ]
    }
   ],
   "source": [
    "root = os.getcwd()\n",
    "data = SpotifyGraph(root, None)\n",
    "g = data.to_nx_graph()\n",
    "print(\"Num nodes:\", len(g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6856\\2261131036.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# if you already have filtered graph you can skip this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# if you already have filtered graph you can skip this\n",
    "data.filter_graph(g, deg=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting projection...\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting projection...\")\n",
    "g = data.get_projected_graph(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_overlapping_algorithms = [#algorithms.aslpaw, \n",
    "                                  algorithms.dcs, \n",
    "                                  algorithms.lais2,\n",
    "                                  #algorithms.overlapping_seed_set_expansion,\n",
    "                                  algorithms.umstmo,\n",
    "                                  algorithms.percomvc,\n",
    "                                  ]\n",
    "print(\"Starting community detection...\\n\")\n",
    "for algo in list_of_overlapping_algorithms:\n",
    "    data.find_communities(g, algo)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # GT_IDS for evaluation after community detection\n",
    "    #playlist_ids, album_ids = dataset.get_playlists_vs_albums()\n",
    "\n",
    "\n",
    "    # hand picked filter words that occour in name or description of the playlists\n",
    "    #keywords = [\"fitness\", \"workout\"]       \n",
    "    #selected_ids = dataset.get_playlists_by_keywords(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "481f671b25a3de7ce29310ade63732b5e6b538537deca2ea013019a2a265f36c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
