{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No protocol specified\n",
      "No protocol specified\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t\t<script type=\"text/javascript\">\n",
       "\t\t\t<!--\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_script');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('script');\n",
       "\t\t\t\telement.type = 'text/javascript';\n",
       "\t\t\t\telement.innerHTML = 'function NetworKit_pageEmbed(id) { var i, j; var elements; elements = document.getElementById(id).getElementsByClassName(\"Plot\"); for (i=0; i<elements.length; i++) { elements[i].id = id + \"_Plot_\" + i; var data = elements[i].getAttribute(\"data-image\").split(\"|\"); elements[i].removeAttribute(\"data-image\"); var content = \"<div class=\\\\\"Image\\\\\" id=\\\\\"\" + elements[i].id + \"_Image\\\\\" />\"; elements[i].innerHTML = content; elements[i].setAttribute(\"data-image-index\", 0); elements[i].setAttribute(\"data-image-length\", data.length); for (j=0; j<data.length; j++) { elements[i].setAttribute(\"data-image-\" + j, data[j]); } NetworKit_plotUpdate(elements[i]); elements[i].onclick = function (e) { NetworKit_overlayShow((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"HeatCell\"); for (i=0; i<elements.length; i++) { var data = parseFloat(elements[i].getAttribute(\"data-heat\")); var color = \"#00FF00\"; if (data <= 1 && data > 0) { color = \"hsla(0, 100%, 75%, \" + (data) + \")\"; } else if (data <= 0 && data >= -1) { color = \"hsla(240, 100%, 75%, \" + (-data) + \")\"; } elements[i].style.backgroundColor = color; } elements = document.getElementById(id).getElementsByClassName(\"Details\"); for (i=0; i<elements.length; i++) { elements[i].setAttribute(\"data-title\", \"-\"); NetworKit_toggleDetails(elements[i]); elements[i].onclick = function (e) { NetworKit_toggleDetails((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"MathValue\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"nan\") { elements[i].parentNode.innerHTML = \"\" } } elements = document.getElementById(id).getElementsByClassName(\"SubCategory\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } elements = document.getElementById(id).getElementsByClassName(\"Category\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } var isFirefox = false; try { isFirefox = typeof InstallTrigger !== \"undefined\"; } catch (e) {} if (!isFirefox) { alert(\"Currently the function\\'s output is only fully supported by Firefox.\"); } } function NetworKit_plotUpdate(source) { var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(source.id + \"_Image\"); image.style.backgroundImage = \"url(\" + data + \")\"; } function NetworKit_showElement(id, show) { var element = document.getElementById(id); element.style.display = (show) ? \"block\" : \"none\"; } function NetworKit_overlayShow(source) { NetworKit_overlayUpdate(source); NetworKit_showElement(\"NetworKit_Overlay\", true); } function NetworKit_overlayUpdate(source) { document.getElementById(\"NetworKit_Overlay_Title\").innerHTML = source.title; var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(\"NetworKit_Overlay_Image\"); image.setAttribute(\"data-id\", source.id); image.style.backgroundImage = \"url(\" + data + \")\"; var link = document.getElementById(\"NetworKit_Overlay_Toolbar_Bottom_Save\"); link.href = data; link.download = source.title + \".svg\"; } function NetworKit_overlayImageShift(delta) { var image = document.getElementById(\"NetworKit_Overlay_Image\"); var source = document.getElementById(image.getAttribute(\"data-id\")); var index = parseInt(source.getAttribute(\"data-image-index\")); var length = parseInt(source.getAttribute(\"data-image-length\")); var index = (index+delta) % length; if (index < 0) { index = length + index; } source.setAttribute(\"data-image-index\", index); NetworKit_overlayUpdate(source); } function NetworKit_toggleDetails(source) { var childs = source.children; var show = false; if (source.getAttribute(\"data-title\") == \"-\") { source.setAttribute(\"data-title\", \"+\"); show = false; } else { source.setAttribute(\"data-title\", \"-\"); show = true; } for (i=0; i<childs.length; i++) { if (show) { childs[i].style.display = \"block\"; } else { childs[i].style.display = \"none\"; } } }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_script');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_style');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('style');\n",
       "\t\t\t\telement.type = 'text/css';\n",
       "\t\t\t\telement.innerHTML = '.NetworKit_Page { font-family: Arial, Helvetica, sans-serif; font-size: 14px; } .NetworKit_Page .Value:before { font-family: Arial, Helvetica, sans-serif; font-size: 1.05em; content: attr(data-title) \":\"; margin-left: -2.5em; padding-right: 0.5em; } .NetworKit_Page .Details .Value:before { display: block; } .NetworKit_Page .Value { font-family: monospace; white-space: pre; padding-left: 2.5em; white-space: -moz-pre-wrap !important; white-space: -pre-wrap; white-space: -o-pre-wrap; white-space: pre-wrap; word-wrap: break-word; tab-size: 4; -moz-tab-size: 4; } .NetworKit_Page .Category { clear: both; padding-left: 1em; margin-bottom: 1.5em; } .NetworKit_Page .Category:before { content: attr(data-title); font-size: 1.75em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory { margin-bottom: 1.5em; padding-left: 1em; } .NetworKit_Page .SubCategory:before { font-size: 1.6em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory[data-title]:before { content: attr(data-title); } .NetworKit_Page .Block { display: block; } .NetworKit_Page .Block:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .Block .Thumbnail_Overview, .NetworKit_Page .Block .Thumbnail_ScatterPlot { width: 260px; float: left; } .NetworKit_Page .Block .Thumbnail_Overview img, .NetworKit_Page .Block .Thumbnail_ScatterPlot img { width: 260px; } .NetworKit_Page .Block .Thumbnail_Overview:before, .NetworKit_Page .Block .Thumbnail_ScatterPlot:before { display: block; text-align: center; font-weight: bold; } .NetworKit_Page .Block .Thumbnail_Overview:before { content: attr(data-title); } .NetworKit_Page .HeatCell { font-family: \"Courier New\", Courier, monospace; cursor: pointer; } .NetworKit_Page .HeatCell, .NetworKit_Page .HeatCellName { display: inline; padding: 0.1em; margin-right: 2px; background-color: #FFFFFF } .NetworKit_Page .HeatCellName { margin-left: 0.25em; } .NetworKit_Page .HeatCell:before { content: attr(data-heat); display: inline-block; color: #000000; width: 4em; text-align: center; } .NetworKit_Page .Measure { clear: both; } .NetworKit_Page .Measure .Details { cursor: pointer; } .NetworKit_Page .Measure .Details:before { content: \"[\" attr(data-title) \"]\"; display: block; } .NetworKit_Page .Measure .Details .Value { border-left: 1px dotted black; margin-left: 0.4em; padding-left: 3.5em; pointer-events: none; } .NetworKit_Page .Measure .Details .Spacer:before { content: \".\"; opacity: 0.0; pointer-events: none; } .NetworKit_Page .Measure .Plot { width: 440px; height: 440px; cursor: pointer; float: left; margin-left: -0.9em; margin-right: 20px; } .NetworKit_Page .Measure .Plot .Image { background-repeat: no-repeat; background-position: center center; background-size: contain; height: 100%; pointer-events: none; } .NetworKit_Page .Measure .Stat { width: 500px; float: left; } .NetworKit_Page .Measure .Stat .Group { padding-left: 1.25em; margin-bottom: 0.75em; } .NetworKit_Page .Measure .Stat .Group .Title { font-size: 1.1em; display: block; margin-bottom: 0.3em; margin-left: -0.75em; border-right-style: dotted; border-right-width: 1px; border-bottom-style: dotted; border-bottom-width: 1px; background-color: #D0D0D0; padding-left: 0.2em; } .NetworKit_Page .Measure .Stat .Group .List { -webkit-column-count: 3; -moz-column-count: 3; column-count: 3; } .NetworKit_Page .Measure .Stat .Group .List .Entry { position: relative; line-height: 1.75em; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:before { position: absolute; left: 0; top: -40px; background-color: #808080; color: #ffffff; height: 30px; line-height: 30px; border-radius: 5px; padding: 0 15px; content: attr(data-tooltip); white-space: nowrap; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:after { position: absolute; left: 15px; top: -10px; border-top: 7px solid #808080; border-left: 7px solid transparent; border-right: 7px solid transparent; content: \"\"; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:after, .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:before { display: block; } .NetworKit_Page .Measure .Stat .Group .List .Entry .MathValue { font-family: \"Courier New\", Courier, monospace; } .NetworKit_Page .Measure:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .PartitionPie { clear: both; } .NetworKit_Page .PartitionPie img { width: 600px; } #NetworKit_Overlay { left: 0px; top: 0px; display: none; position: absolute; width: 100%; height: 100%; background-color: rgba(0,0,0,0.6); z-index: 1000; } #NetworKit_Overlay_Title { position: absolute; color: white; transform: rotate(-90deg); width: 32em; height: 32em; padding-right: 0.5em; padding-top: 0.5em; text-align: right; font-size: 40px; } #NetworKit_Overlay .button { background: white; cursor: pointer; } #NetworKit_Overlay .button:before { size: 13px; display: inline-block; text-align: center; margin-top: 0.5em; margin-bottom: 0.5em; width: 1.5em; height: 1.5em; } #NetworKit_Overlay .icon-close:before { content: \"X\"; } #NetworKit_Overlay .icon-previous:before { content: \"P\"; } #NetworKit_Overlay .icon-next:before { content: \"N\"; } #NetworKit_Overlay .icon-save:before { content: \"S\"; } #NetworKit_Overlay_Toolbar_Top, #NetworKit_Overlay_Toolbar_Bottom { position: absolute; width: 40px; right: 13px; text-align: right; z-index: 1100; } #NetworKit_Overlay_Toolbar_Top { top: 0.5em; } #NetworKit_Overlay_Toolbar_Bottom { Bottom: 0.5em; } #NetworKit_Overlay_ImageContainer { position: absolute; top: 5%; left: 5%; height: 90%; width: 90%; background-repeat: no-repeat; background-position: center center; background-size: contain; } #NetworKit_Overlay_Image { height: 100%; width: 100%; background-repeat: no-repeat; background-position: center center; background-size: contain; }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_style');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_Overlay');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('div');\n",
       "\t\t\t\telement.innerHTML = '<div id=\"NetworKit_Overlay_Toolbar_Top\"><div class=\"button icon-close\" id=\"NetworKit_Overlay_Close\" /></div><div id=\"NetworKit_Overlay_Title\" /> <div id=\"NetworKit_Overlay_ImageContainer\"> <div id=\"NetworKit_Overlay_Image\" /> </div> <div id=\"NetworKit_Overlay_Toolbar_Bottom\"> <div class=\"button icon-previous\" onclick=\"NetworKit_overlayImageShift(-1)\" /> <div class=\"button icon-next\" onclick=\"NetworKit_overlayImageShift(1)\" /> <a id=\"NetworKit_Overlay_Toolbar_Bottom_Save\"><div class=\"button icon-save\" /></a> </div>';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_Overlay');\n",
       "\t\t\t\tdocument.body.appendChild(element);\n",
       "\t\t\t\tdocument.getElementById('NetworKit_Overlay_Close').onclick = function (e) {\n",
       "\t\t\t\t\tdocument.getElementById('NetworKit_Overlay').style.display = 'none';\n",
       "\t\t\t\t}\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t-->\n",
       "\t\t\t</script>\n",
       "\t\t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from interruptingcow import timeout\n",
    "\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "from cdlib import algorithms, classes, evaluation, readwrite\n",
    "\n",
    "class SpotifyGraph():\n",
    "\n",
    "    def __init__(self, dir, features_dir):\n",
    "\n",
    "        self.base_dir = path.join(dir, \"dataset\")\n",
    "        self.save_dir = path.join(dir, \"results\")\n",
    "        self.tracks_pth = path.join(self.base_dir, \"tracks.json\")\n",
    "        self.col_pth = path.join(self.base_dir, \"collections.json\")\n",
    "        self.graph_pth = path.join(self.base_dir, \"graph.json\")\n",
    "\n",
    "        self.ft_dir = features_dir\n",
    "        self.features_dict = {}\n",
    "\n",
    "        self.load()\n",
    "\n",
    "    def load(self):\n",
    "        print(\"Loading graph...\")\n",
    "        # with open(self.tracks_pth, \"r\", encoding=\"utf-8\") as f:\n",
    "        #     self.tracks = json.load(f)\n",
    "        # with open(self.col_pth, \"r\", encoding=\"utf-8\") as f:\n",
    "        #     self.collections = json.load(f)\n",
    "        with open(self.graph_pth, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.graph = json.load(f)\n",
    "\n",
    "    def save_graph(self, G):\n",
    "        with open(path.join(self.base_dir, \"filtered_graph.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(dict(tracks=[n for n in G.nodes() if n in self.track_ids_deg.keys()],\n",
    "                           collections=[n for n in G.nodes() if n in self.col_ids_deg.keys()],\n",
    "                           edges=[{\"from\" : u, \"to\" : v} for u,v in G.edges()]),\n",
    "                           f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    def to_nx_graph(self):\n",
    "        '''Get dataset as a NetworkX graph.'''\n",
    "        \n",
    "        g = nx.Graph()\n",
    "        g.add_nodes_from(self.graph[\"collections\"], bipartite=0)\n",
    "        g.add_nodes_from(self.graph[\"tracks\"], bipartite=1) \n",
    "        edge_tuples = [ (e[\"from\"], e[\"to\"]) for e in self.graph[\"edges\"] ] \n",
    "        g.add_edges_from( edge_tuples )\n",
    "\n",
    "        self.track_ids_deg = {i : g.degree[i] for i in self.graph[\"tracks\"]}\n",
    "        self.col_ids_deg = {i : g.degree[i] for i in self.graph[\"collections\"]}\n",
    "\n",
    "        return g#, track_ids_deg, col_ids_deg\n",
    "\n",
    "    def filter_graph(self, g, deg=1):\n",
    "        print(\"Removing nodes with k<={}...\".format(deg))\n",
    "        print(\"Num nodes before filter: {}\".format(len(g.nodes)))\n",
    "        nodes_to_remove = [i for (i, d) in self.track_ids_deg.items() if d <= deg]\n",
    "        g.remove_nodes_from(nodes_to_remove)\n",
    "        # nodes_to_remove = [i for (i, d) in self.track_ids_deg.items() if d >= 51 and d <= 53]\n",
    "        # g.remove_nodes_from(nodes_to_remove)\n",
    "        print(\"Num nodes after filter: {}\".format(len(g.nodes)))\n",
    "        largest_cc = max(nx.connected_components(g), key=len)\n",
    "        print(\"Largest 5 CCs: \", [len(c) for c in sorted(nx.connected_components(g), key=len, reverse=True)][:5])\n",
    "        print(\"Num nodes final: {}\".format(len(largest_cc)))\n",
    "        print(\"Saving new graph...\")\n",
    "        g = g.subgraph(largest_cc)\n",
    "        self.save_graph(g)\n",
    "        return g\n",
    "\n",
    "\n",
    "    def get_playlists_vs_albums(self):\n",
    "        playlist_ids, album_ids = [],[]\n",
    "        for id,info in self.collections.items():\n",
    "            if \"playlist\" in info[\"type\"]:\n",
    "                playlist_ids.append(id)\n",
    "            elif \"album\" in info[\"type\"]:\n",
    "                album_ids.append(id)\n",
    "\n",
    "        return playlist_ids, album_ids\n",
    "    \n",
    "    def get_playlists_by_keywords(self, keywords):\n",
    "        playlist_ids = []\n",
    "\n",
    "        def keywords_in_info(keywords, info):\n",
    "            return True if (any(word in info[\"name\"].lower() for word in keywords) or \\\n",
    "                            any(word in info[\"description\"].lower() for word in keywords)) else False\n",
    "\n",
    "        for id,info in self.collections.items():\n",
    "            if \"playlist\" in info[\"type\"] and keywords_in_info(keywords, info):\n",
    "                playlist_ids.append(id)\n",
    "\n",
    "        return playlist_ids\n",
    "    \n",
    "    def get_projected_graph(self, graph, is_multigraph=False):\n",
    "        nodes_for_projection = [n for n, a in graph.nodes(data=True) if a[\"bipartite\"]==1]\n",
    "        print(\"Projecting on {} nodes\".format(len(nodes_for_projection)))\n",
    "        G_projected = bipartite.projected_graph(graph, nodes_for_projection, multigraph=is_multigraph)\n",
    "        return G_projected\n",
    "    \n",
    "    def get_custom_projected_graph(self, graph, is_multigraph=False):\n",
    "        with open(\"dataset/custom_communities_corrected.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            comm = json.load(f)\n",
    "        nodes_for_projection, nodes_for_projection_t, nodes_for_projection_c = [],[],[]\n",
    "        for tracks in comm[\"tracks\"].values():\n",
    "            nodes_for_projection_t += tracks\n",
    "        print(\"Tracks: \", len(nodes_for_projection_t))\n",
    "        for col in comm[\"collections\"].values():\n",
    "            nodes_for_projection_c += col\n",
    "        print(\"Collections: \", len(nodes_for_projection_c))\n",
    "\n",
    "        nodes_for_subgraph = nodes_for_projection_t + nodes_for_projection_c\n",
    "        nodes_for_subgraph = list(set(nodes_for_subgraph))\n",
    "        print(\"Nodes w/o duplicates: \",len(nodes_for_subgraph))\n",
    "        g = graph.subgraph(nodes_for_subgraph)\n",
    "        print(\"Total CCs: \", len([len(c) for c in sorted(nx.connected_components(g), key=len, reverse=True)]))\n",
    "        print(\"Largest 5 CCs: \", [len(c) for c in sorted(nx.connected_components(g), key=len, reverse=True)][:5])\n",
    "        print(\"Smallest 5 CCs: \", [len(c) for c in sorted(nx.connected_components(g), key=len, reverse=False)][:5])\n",
    "        \n",
    "        largest_cc = max(nx.connected_components(g), key=len)\n",
    "        G_bipartite = graph.subgraph(largest_cc)\n",
    "        print(list(G_bipartite.nodes(data=True))[:2])\n",
    "        nodes_for_projection_t = [n for n in nodes_for_projection_t if n in G_bipartite.nodes()]\n",
    "        nodes_for_projection_c = [n for n in nodes_for_projection_c if n in G_bipartite.nodes()]\n",
    "        print(\"Projecting on {} nodes\".format(len(set(nodes_for_projection_t))))\n",
    "\n",
    "        G_projected = bipartite.projected_graph(G_bipartite, nodes_for_projection_t, multigraph=is_multigraph)\n",
    "        return G_projected, G_bipartite\n",
    "    \n",
    "    def save_community(self, pred, algo_name):\n",
    "        readwrite.write_community_csv(pred, path.join(self.save_dir, \"{}_communities.csv\".format(algo_name)), \",\")\n",
    "\n",
    "    def find_communities(self, g, algorithm):\n",
    "        algorithm_name = algorithm.__name__\n",
    "        try:\n",
    "            with timeout(60*35, exception=RuntimeError):\n",
    "                print(\"Starting community detection for {} algorithm\".format(algorithm_name))\n",
    "                if algorithm_name == \"angel\":\n",
    "                    community_prediction = algorithm(g, threshold=0.3, min_community_size=5000)\n",
    "                elif algorithm_name == \"node_perception\":\n",
    "                    community_prediction = algorithm(g, threshold=0.3, overlap_threshold=0.3, min_comm_size=5000)\n",
    "                elif algorithm_name == \"CPM_Bipartite\":\n",
    "                    community_prediction = algorithm(g, 0.3)\n",
    "                elif algorithm_name == \"spectral\":\n",
    "                    community_prediction = algorithm(g, kmax=17)\n",
    "                elif algorithm_name == \"frc_fgsn\":\n",
    "                    community_prediction = algorithm(g, theta=0.3, eps=0.6, r=50)\n",
    "                elif algorithm_name == \"principled_clustering\":\n",
    "                    community_prediction = algorithm(g, cluster_count=17)\n",
    "                else: \n",
    "                    community_prediction = algorithm(g)\n",
    "                print(\"Saving...\")\n",
    "                self.save_community(community_prediction, algorithm_name)\n",
    "        except Exception as e:\n",
    "            print(\"Error with {} algorithm\".format(algorithm_name))\n",
    "            print(type(e), e)\n",
    "        else:\n",
    "            print(\"Saved communities file for {} algorithm\".format(algorithm_name))\n",
    "\n",
    "    def find_common_keywords(self):\n",
    "        all_keywords = defaultdict(int)\n",
    "        for id, info in tqdm(self.collections.items()):\n",
    "            if \"playlist\" in info[\"type\"]:\n",
    "                if \"<a href=:\" in info[\"description\"]:\n",
    "                    decription = []\n",
    "                    for i in info[\"description\"].split(\", \"):\n",
    "                        decription += i.lower().split(\">\")[1].split(\"</a\")[0].split()\n",
    "                else:\n",
    "                    decription = info[\"description\"].lower()\\\n",
    "                                .replace(\"(\",\"\").replace(\")\",\"\").replace(\"{\",\"\").replace(\"}\",\"\")\\\n",
    "                                .replace(\"[\",\"\").replace(\"]\",\"\").replace(\"!\",\"\").replace(\"?\",\"\")\\\n",
    "                                .replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\"\").replace(\".\",\"\")\\\n",
    "                                .replace(\"-\",\"\").replace(\"–\",\"\").replace(\";\",\"\").replace(\":\",\"\")\\\n",
    "                                .replace(\"&\",\"\").replace(\"%\",\"\").replace(\"/\",\"\").replace(\"\\\\\",\"\")\\\n",
    "                                .replace(\"$\",\"\").replace(\"|\",\"\").split()\n",
    "\n",
    "                name = info[\"name\"].lower()\\\n",
    "                                .replace(\"(\",\"\").replace(\")\",\"\").replace(\"{\",\"\").replace(\"}\",\"\")\\\n",
    "                                .replace(\"[\",\"\").replace(\"]\",\"\").replace(\"!\",\"\").replace(\"?\",\"\")\\\n",
    "                                .replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\"\").replace(\".\",\"\")\\\n",
    "                                .replace(\"-\",\"\").replace(\"–\",\"\").replace(\";\",\"\").replace(\":\",\"\")\\\n",
    "                                .replace(\"&\",\"\").replace(\"%\",\"\").replace(\"/\",\"\").replace(\"\\\\\",\"\")\\\n",
    "                                .replace(\"$\",\"\").replace(\"|\",\"\").split()\n",
    "                \n",
    "                for word in name + decription:\n",
    "                    all_keywords[word] += 1\n",
    "        \n",
    "        \n",
    "        with open(path.join(self.base_dir, \"phrases.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(dict(phrases=dict(sorted(all_keywords.items(), key=lambda item: item[1], reverse=True))), \\\n",
    "                            f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # Example usage of the SpotifyGraph dataset class\n",
    "    \n",
    "\n",
    "    # JSON COLLECTIONS STRUCTURE FOR EACH PLAYLIST - example\n",
    "    # \"type\": \"playlist\",\n",
    "    # \"name\": \"Adrenaline Workout\",\n",
    "    # \"num_tracks\": 31,\n",
    "    # \"description\": \"If your workout doubles as an outlet for your aggression\",\n",
    "    # \"ztracks\": [ track ids ]\n",
    "\n",
    "\n",
    "# to je iz hw3 sam sample \n",
    "\n",
    "            # g = girvan_newman_graph(mi)\n",
    "            # louvain = algorithms.louvain(g)\n",
    "            # walktrap = algorithms.walktrap(g)\n",
    "            # label_prop = algorithms.label_propagation(g)\n",
    "            # true_labels = classes.NodeClustering([[3*i + j for i in range(24)] for j in range(3)], g)\n",
    "\n",
    "            # a += evaluation.normalized_mutual_information(true_labels, louvain).score\n",
    "            # b += evaluation.normalized_mutual_information(true_labels, walktrap).score\n",
    "            # c += evaluation.normalized_mutual_information(true_labels, label_prop).score\n",
    "\n",
    "            ##############################################################################\n",
    "\n",
    "            # truth = [[i for i in range(1000)]]\n",
    "            # g = nx.gnm_random_graph(1000, 1000*k)\n",
    "            # true_labels = classes.NodeClustering(truth, g)\n",
    "            # louvain = algorithms.louvain(g)\n",
    "            # walktrap = algorithms.walktrap(g)\n",
    "            # label_prop = algorithms.label_propagation(g)\n",
    "\n",
    "            # a += evaluation.variation_of_information(true_labels, louvain).score\n",
    "            # b += evaluation.variation_of_information(true_labels, walktrap).score\n",
    "            # c += evaluation.variation_of_information(true_labels, label_prop).score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph...\n",
      "Num nodes: 1563358\n",
      "Bipartite? True\n"
     ]
    }
   ],
   "source": [
    "root = os.getcwd()\n",
    "data = SpotifyGraph(root, None)\n",
    "g = data.to_nx_graph()\n",
    "print(\"Num nodes:\", len(g))\n",
    "#data.find_common_keywords()\n",
    "print(\"Bipartite?\", bipartite.is_bipartite(g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you already have filtered graph you can skip this\n",
    "#g = data.filter_graph(g, deg=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting projection...\n",
      "1563358 True\n",
      "Tracks:  277018\n",
      "Collections:  11625\n",
      "Nodes w/o duplicates:  236889\n",
      "Total CCs:  1\n",
      "Largest 5 CCs:  [236889]\n",
      "Smallest 5 CCs:  [236889]\n",
      "[('4Ro8BiPvl9JoW2uCipmbbm', {'bipartite': 1}), ('0w46TUUSox8pvbNJ6Wxhwu', {'bipartite': 1})]\n",
      "Projecting on 225264 nodes\n",
      "225264 False\n",
      "236889 True\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting projection...\")\n",
    "#g_ = data.get_projected_graph(g)\n",
    "print(len(g.nodes), bipartite.is_bipartite(g))\n",
    "g_, gb_ = data.get_custom_projected_graph(g)\n",
    "print(len(g_.nodes), bipartite.is_bipartite(g_))\n",
    "print(len(gb_.nodes), bipartite.is_bipartite(gb_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CCs:  1\n",
      "Largest 5 CCs:  [225264]\n"
     ]
    }
   ],
   "source": [
    "largest_cc = max(nx.connected_components(g_), key=len)\n",
    "\n",
    "print(\"Total CCs: \", len([len(c) for c in sorted(nx.connected_components(g_), key=len, reverse=True)]))\n",
    "print(\"Largest 5 CCs: \", [len(c) for c in sorted(nx.connected_components(g_), key=len, reverse=True)][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_overlapping_algorithms = [algorithms.principled_clustering,\n",
    "                                  algorithms.frc_fgsn,\n",
    "                                  algorithms.angel,\n",
    "                                  algorithms.core_expansion,\n",
    "                                  algorithms.node_perception,\n",
    "                                  algorithms.lpanni,\n",
    "                                  algorithms.graph_entropy,\n",
    "                                  algorithms.umstmo,\n",
    "\n",
    "                                  algorithms.lemon,\n",
    "                                  algorithms.multicom,\n",
    "                                  algorithms.overlapping_seed_set_expansion,\n",
    "                                  ]\n",
    "list_of_crisp_algorithms = [algorithms.leiden, \n",
    "                            algorithms.infomap, \n",
    "                            algorithms.sbm_dl,\n",
    "                            ]\n",
    "list_of_bipartite_algorithms = [algorithms.bimlpa, \n",
    "                                algorithms.condor,\n",
    "                                algorithms.CPM_Bipartite,\n",
    "                                algorithms.infomap_bipartite,\n",
    "                                algorithms.spectral,\n",
    "                                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting community detection...\n",
      "\n",
      "Starting community detection for condor algorithm\n",
      "Error with condor algorithm\n",
      "<class 'AssertionError'> The network must be bipartite.\n",
      "\n",
      "Starting community detection for CPM_Bipartite algorithm\n",
      "Error with CPM_Bipartite algorithm\n",
      "<class 'ValueError'> invalid literal for int() with base 10: '7Mj1kQLaqu6Rr6rwAIJQQh'\n",
      "\n",
      "Starting community detection for spectral algorithm\n",
      "Error with spectral algorithm\n",
      "<class 'numpy.core._exceptions._ArrayMemoryError'> Unable to allocate 378. GiB for an array with shape (225264, 225264) and data type int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting community detection...\\n\")\n",
    "\n",
    "for algo in list_of_overlapping_algorithms:\n",
    "    data.find_communities(g_, algo)\n",
    "    print()\n",
    "# for algo in list_of_bipartite_algorithms:\n",
    "#     data.find_communities(gb_, algo)\n",
    "#     print()\n",
    "# for algo in list_of_crisp_algorithms:\n",
    "#     data.find_communities(g_, algo)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236889 [('4Ro8BiPvl9JoW2uCipmbbm', {'bipartite': 1, 'node_id': '4Ro8BiPvl9JoW2uCipmbbm'}), ('0w46TUUSox8pvbNJ6Wxhwu', {'bipartite': 1, 'node_id': '0w46TUUSox8pvbNJ6Wxhwu'})]\n",
      "236889 [(0, {'bipartite': 1, 'node_id': '4Ro8BiPvl9JoW2uCipmbbm'}), (1, {'bipartite': 1, 'node_id': '0w46TUUSox8pvbNJ6Wxhwu'})]\n"
     ]
    }
   ],
   "source": [
    "def add_node_id_attr(G):\n",
    "    mapping = {}\n",
    "    for i, (n, a) in enumerate(G.nodes(data=True)):\n",
    "        a[\"node_id\"] = n\n",
    "        mapping[n] = i\n",
    "    return G, mapping\n",
    "\n",
    "gb_, mapping = add_node_id_attr(gb_)\n",
    "gb_relabeled = nx.relabel_nodes(gb_, mapping)\n",
    "print(len(gb_.nodes(data=True)), list(gb_.nodes(data=True))[:2])\n",
    "print(len(gb_relabeled.nodes(data=True)), list(gb_relabeled.nodes(data=True))[:2])\n",
    "\n",
    "# for algo in list_of_bipartite_algorithms:\n",
    "#     data.find_communities(gb_relabeled, algo)\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225264 [('2aQqCFzqHLzwUtZfunyckh', {'bipartite': 1, 'node_id': '2aQqCFzqHLzwUtZfunyckh'}), ('1x0wsc1w83gfYRf4UgMvQm', {'bipartite': 1, 'node_id': '1x0wsc1w83gfYRf4UgMvQm'})]\n",
      "225264 [('2aQqCFzqHLzwUtZfunyckh', {'bipartite': 1, 'node_id': '2aQqCFzqHLzwUtZfunyckh'}), ('1x0wsc1w83gfYRf4UgMvQm', {'bipartite': 1, 'node_id': '1x0wsc1w83gfYRf4UgMvQm'})]\n",
      "225264\n"
     ]
    }
   ],
   "source": [
    "print(len(g_.nodes(data=True)), list(g_.nodes(data=True))[:2])\n",
    "g_, mapping = add_node_id_attr(g_)\n",
    "print(len(g_.nodes(data=True)), list(g_.nodes(data=True))[:2])\n",
    "def get_gt_clustering(G):\n",
    "    P = {}\n",
    "    with open(\"dataset/custom_communities_corrected.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        P = json.load(f)\n",
    "            \n",
    "    return classes.NodeClustering(list(P[\"tracks\"].values()), G, 'Truth')\n",
    "\n",
    "overlapping_gt = get_gt_clustering(g_)\n",
    "c = []\n",
    "for com in overlapping_gt.communities:\n",
    "    c += com\n",
    "c = set(c)\n",
    "print(len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "leiden:\n",
      "Discovered 225264/225264 nodes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [277018, 225264]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/lukak/UNI/ina/ina-project/test.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000009vscode-remote?line=17'>18</a>\u001b[0m nf1 \u001b[39m=\u001b[39m evaluation\u001b[39m.\u001b[39mnf1(overlapping_gt, prediction)\u001b[39m.\u001b[39mscore\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000009vscode-remote?line=18'>19</a>\u001b[0m f1 \u001b[39m=\u001b[39m evaluation\u001b[39m.\u001b[39mf1(overlapping_gt, prediction)\u001b[39m.\u001b[39mscore\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000009vscode-remote?line=19'>20</a>\u001b[0m nmi \u001b[39m=\u001b[39m evaluation\u001b[39m.\u001b[39;49mnormalized_mutual_information(overlapping_gt, prediction)\u001b[39m.\u001b[39mscore\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000009vscode-remote?line=20'>21</a>\u001b[0m \u001b[39m#omega = evaluation.omega(overlapping_gt, prediction).score\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000009vscode-remote?line=21'>22</a>\u001b[0m \u001b[39m#voi = evaluation.variation_of_information(overlapping_gt, prediction).score\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000009vscode-remote?line=22'>23</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000009vscode-remote?line=23'>24</a>\u001b[0m \u001b[39m#print(\"lfk score:\", lfk)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000009vscode-remote?line=24'>25</a>\u001b[0m \u001b[39m#print(\"mgh score:\", mgh)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B6.tcp.ngrok.io/home/lukak/UNI/ina/ina-project/test.ipynb#ch0000009vscode-remote?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnf1 score:\u001b[39m\u001b[39m\"\u001b[39m, nf1)\n",
      "File \u001b[0;32m~/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/evaluation/comparison.py:99\u001b[0m, in \u001b[0;36mnormalized_mutual_information\u001b[0;34m(first_partition, second_partition)\u001b[0m\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/evaluation/comparison.py?line=83'>84</a>\u001b[0m second_partition_c \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/evaluation/comparison.py?line=84'>85</a>\u001b[0m     x[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/evaluation/comparison.py?line=85'>86</a>\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/evaluation/comparison.py?line=92'>93</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/evaluation/comparison.py?line=93'>94</a>\u001b[0m ]\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/evaluation/comparison.py?line=95'>96</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m normalized_mutual_info_score\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/evaluation/comparison.py?line=97'>98</a>\u001b[0m \u001b[39mreturn\u001b[39;00m MatchingResult(\n\u001b[0;32m---> <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/evaluation/comparison.py?line=98'>99</a>\u001b[0m     score\u001b[39m=\u001b[39mnormalized_mutual_info_score(first_partition_c, second_partition_c)\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/cdlib/evaluation/comparison.py?line=99'>100</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py:1028\u001b[0m, in \u001b[0;36mnormalized_mutual_info_score\u001b[0;34m(labels_true, labels_pred, average_method)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py?line=950'>951</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnormalized_mutual_info_score\u001b[39m(\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py?line=951'>952</a>\u001b[0m     labels_true, labels_pred, \u001b[39m*\u001b[39m, average_method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marithmetic\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py?line=952'>953</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py?line=953'>954</a>\u001b[0m     \u001b[39m\"\"\"Normalized Mutual Information between two clusterings.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py?line=954'>955</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py?line=955'>956</a>\u001b[0m \u001b[39m    Normalized Mutual Information (NMI) is a normalization of the Mutual\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py?line=1025'>1026</a>\u001b[0m \u001b[39m      0.0\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py?line=1026'>1027</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py?line=1027'>1028</a>\u001b[0m     labels_true, labels_pred \u001b[39m=\u001b[39m check_clusterings(labels_true, labels_pred)\n\u001b[1;32m   <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py?line=1028'>1029</a>\u001b[0m     classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(labels_true)\n\u001b[1;32m   <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py?line=1029'>1030</a>\u001b[0m     clusters \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(labels_pred)\n",
      "File \u001b[0;32m~/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py:71\u001b[0m, in \u001b[0;36mcheck_clusterings\u001b[0;34m(labels_true, labels_pred)\u001b[0m\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py?line=68'>69</a>\u001b[0m \u001b[39mif\u001b[39;00m labels_pred\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py?line=69'>70</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mlabels_pred must be 1D: shape is \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (labels_pred\u001b[39m.\u001b[39mshape,))\n\u001b[0;32m---> <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py?line=70'>71</a>\u001b[0m check_consistent_length(labels_true, labels_pred)\n\u001b[1;32m     <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/metrics/cluster/_supervised.py?line=72'>73</a>\u001b[0m \u001b[39mreturn\u001b[39;00m labels_true, labels_pred\n",
      "File \u001b[0;32m~/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/utils/validation.py?line=384'>385</a>\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/utils/validation.py?line=385'>386</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/utils/validation.py?line=386'>387</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/utils/validation.py?line=387'>388</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/utils/validation.py?line=388'>389</a>\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    <a href='file:///home/lukak/anaconda3/envs/ina/lib/python3.8/site-packages/sklearn/utils/validation.py?line=389'>390</a>\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [277018, 225264]"
     ]
    }
   ],
   "source": [
    "results_dir = os.path.join(os.getcwd(),\"results\")\n",
    "results = [i for i in os.listdir(results_dir) if i.endswith(\".csv\")]\n",
    "print(\"Evaluating...\")\n",
    "for algo in list_of_crisp_algorithms:\n",
    "    for result in results:\n",
    "        #print(algo.__name__, result)\n",
    "        if algo.__name__ in result:\n",
    "            print(\"{}:\".format(algo.__name__))\n",
    "            prediction = readwrite.read_community_csv(os.path.join(results_dir,result), \",\", str)\n",
    "            p = []\n",
    "            for com in prediction.communities:\n",
    "                p += com\n",
    "            p = set(p)\n",
    "            print(\"Discovered {}/{} nodes.\".format(len(p),len(c)))\n",
    "            if len(prediction.communities) != 0:\n",
    "                #lfk = evaluation.overlapping_normalized_mutual_information_LFK(overlapping_gt, prediction).score\n",
    "                #mgh = evaluation.overlapping_normalized_mutual_information_MGH(overlapping_gt, prediction).score\n",
    "                nf1 = evaluation.nf1(overlapping_gt, prediction).score\n",
    "                f1 = evaluation.f1(overlapping_gt, prediction).score\n",
    "                nmi = evaluation.normalized_mutual_information(overlapping_gt, prediction).score\n",
    "                #omega = evaluation.omega(overlapping_gt, prediction).score\n",
    "                #voi = evaluation.variation_of_information(overlapping_gt, prediction).score\n",
    "                \n",
    "                #print(\"lfk score:\", lfk)\n",
    "                #print(\"mgh score:\", mgh)\n",
    "                print(\"nf1 score:\", nf1)\n",
    "                print(\"f1 score:\", f1)\n",
    "                print(\"f1 score:\", nmi)\n",
    "                #print(\"omega score:\", omega)\n",
    "                #print(\"voi score:\", voi)\n",
    "                print()\n",
    "            else:\n",
    "                print(\"No detected communities, can not evaluate!\")\n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225264/225264 [12:58<00:00, 289.46it/s]\n",
      "100%|██████████| 11625/11625 [00:01<00:00, 11420.20it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_gt_communities_from_bipartide_graph(G):\n",
    "    track_ids = {}\n",
    "    col_ids = {}\n",
    "    with open(\"dataset/custom_communities.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        comm = json.load(f)\n",
    "\n",
    "    for node, attr in tqdm([(n,a) for n,a in G.nodes(data = True) if a[\"bipartite\"]==1]):\n",
    "        for com, tracks in comm[\"tracks\"].items():\n",
    "            if attr['node_id'] in tracks:\n",
    "                if com not in track_ids:\n",
    "                    track_ids[com] = []\n",
    "                track_ids[com].append(node)\n",
    "    \n",
    "    for node, attr in tqdm([(n,a) for n,a in G.nodes(data = True) if a[\"bipartite\"]==0]):\n",
    "        for com, playlists in comm[\"collections\"].items():\n",
    "            if attr['node_id'] in playlists:\n",
    "                if com not in col_ids:\n",
    "                    col_ids[com] = []\n",
    "                col_ids[com].append(node)\n",
    "\n",
    "    with open(\"dataset/custom_communities_corrected.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(dict(tracks=track_ids,\n",
    "                        collections=col_ids), \\\n",
    "                        f, ensure_ascii=False, indent=4)\n",
    "\n",
    "get_gt_communities_from_bipartide_graph(gb_)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "481f671b25a3de7ce29310ade63732b5e6b538537deca2ea013019a2a265f36c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
